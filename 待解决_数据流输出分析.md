# æ•°æ®æµè¾“å‡ºé—®é¢˜åˆ†æ

## é—®é¢˜æè¿°

è°ƒç”¨APIæ—¶ï¼Œåç«¯æœåŠ¡å™¨æ§åˆ¶å°æ˜¾ç¤ºäº†è¯¦ç»†çš„çŠ¶æ€ä¿¡æ¯ï¼ˆè¯·æ±‚/å“åº”æ—¥å¿—ã€è½®è¯¢è¿›åº¦ç­‰ï¼‰ï¼Œä½†ç½‘ç«™å®¢æˆ·ç«¯çœ‹ä¸åˆ°è¿™äº›å®æ—¶çŠ¶æ€æ›´æ–°ã€‚

## æ ¹æœ¬åŸå› 

### 1. **ä¸¤ä¸ªç‹¬ç«‹çš„è¾“å‡ºé€šé“**

#### åç«¯æ§åˆ¶å°æ—¥å¿—ï¼ˆä½ çœ‹åˆ°çš„ï¼‰
```
ğŸ”µ [REQUEST] 2025-12-28 02:21:31.074
Method: POST
URL: https://sora.chatgpt.com/backend/nf/create
...
â„¹ï¸  [2025-12-28 02:21:32.717] Starting task polling: task_id=task_01kdhc5jkkfy5sn6eqcd507v21
â„¹ï¸  [2025-12-28 02:21:38.259] Task task_01kdhc5jkkfy5sn6eqcd507v21 progress: 9% (status: running)
```

è¿™äº›æ˜¯**æœåŠ¡å™¨ç«¯çš„è°ƒè¯•æ—¥å¿—**ï¼Œé€šè¿‡`debug_logger`è¾“å‡ºåˆ°æ§åˆ¶å°ï¼Œ**ä¸ä¼šå‘é€ç»™å®¢æˆ·ç«¯**ã€‚

#### SSEæµï¼ˆå®¢æˆ·ç«¯åº”è¯¥æ”¶åˆ°çš„ï¼‰
```
data: {"choices":[{"delta":{"reasoning_content":"**Video Generation Progress**: 9% (running)\n"}}]}

data: {"choices":[{"delta":{"reasoning_content":"**Video Generation Progress**: 15% (running)\n"}}]}
```

è¿™äº›æ˜¯é€šè¿‡`yield self._format_stream_chunk()`å‘é€çš„**SSEäº‹ä»¶**ï¼Œå®¢æˆ·ç«¯å¯ä»¥æ¥æ”¶ã€‚

### 2. **å½“å‰ä»£ç çš„é—®é¢˜**

æŸ¥çœ‹`generation_handler.py`çš„`_poll_task_result`æ–¹æ³•ï¼ˆç¬¬753-758è¡Œï¼‰ï¼š

```python
# Output status every 30 seconds (not just when progress changes)
current_time = time.time()
if stream and (current_time - last_status_output_time >= video_status_interval):
    last_status_output_time = current_time
    debug_logger.log_info(f"Task {task_id} progress: {progress_pct}% (status: {status})")
    yield self._format_stream_chunk(
        reasoning_content=f"**Video Generation Progress**: {progress_pct}% ({status})\\n"
    )
```

**é—®é¢˜ç‚¹**ï¼š
- åªåœ¨`video_status_interval`ï¼ˆ5ç§’ï¼‰é—´éš”æ—¶æ‰å‘é€è¿›åº¦æ›´æ–°
- ä½†å®é™…è½®è¯¢é—´éš”æ˜¯`poll_interval`ï¼ˆé€šå¸¸2.5ç§’ï¼‰ï¼Œä¸­é—´çš„è½®è¯¢ç»“æœ**æ²¡æœ‰å‘é€ç»™å®¢æˆ·ç«¯**
- æ‰€æœ‰çš„`debug_logger.log_info`è°ƒç”¨åªè¾“å‡ºåˆ°æœåŠ¡å™¨æ§åˆ¶å°ï¼Œ**ä¸å‘é€SSE**

## æ•°æ®æµå¯¹æ¯”

### å½“å‰å®é™…æµç¨‹

```
åç«¯è½®è¯¢å¾ªç¯ï¼ˆæ¯2.5ç§’ï¼‰:
â”œâ”€ ç¬¬1æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âŒ
â”œâ”€ ç¬¬2æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âœ… (æ»¡è¶³5ç§’é—´éš”)
â”œâ”€ ç¬¬3æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âŒ
â”œâ”€ ç¬¬4æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âœ… (æ»¡è¶³5ç§’é—´éš”)
â””â”€ ...
```

### æœŸæœ›çš„æµç¨‹

```
åç«¯è½®è¯¢å¾ªç¯ï¼ˆæ¯2.5ç§’ï¼‰:
â”œâ”€ ç¬¬1æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âœ…
â”œâ”€ ç¬¬2æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âœ…
â”œâ”€ ç¬¬3æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âœ…
â”œâ”€ ç¬¬4æ¬¡è½®è¯¢ â†’ debug_loggerè¾“å‡ºåˆ°æ§åˆ¶å° âœ… â†’ SSEå‘é€ç»™å®¢æˆ·ç«¯ âœ…
â””â”€ ...
```

## è§£å†³æ–¹æ¡ˆ

### æ–¹æ¡ˆ1ï¼šå¢åŠ æ›´å¤šSSEçŠ¶æ€æ¨é€ï¼ˆæ¨èï¼‰

ä¿®æ”¹`_poll_task_result`æ–¹æ³•ï¼Œåœ¨å…³é”®æ­¥éª¤éƒ½å‘é€SSEæ›´æ–°ï¼š

```python
async def _poll_task_result(self, task_id: str, token: str, is_video: bool,
                            stream: bool, prompt: str, token_id: int = None) -> AsyncGenerator[str, None]:
    # ... åˆå§‹åŒ–ä»£ç  ...
    
    for attempt in range(max_attempts):
        await asyncio.sleep(poll_interval)
        
        try:
            if is_video:
                # 1. å‘é€"æ­£åœ¨æ£€æŸ¥çŠ¶æ€"çš„SSE
                if stream:
                    yield self._format_stream_chunk(
                        reasoning_content=f"Checking task status (attempt {attempt + 1}/{max_attempts})...\\n"
                    )
                
                # 2. è·å–pending tasks
                pending_tasks = await self.sora_client.get_pending_tasks(token)
                
                # 3. å‘é€"æ”¶åˆ°å“åº”"çš„SSE
                if stream:
                    yield self._format_stream_chunk(
                        reasoning_content=f"Received response with {len(pending_tasks)} pending tasks\\n"
                    )
                
                # 4. æŸ¥æ‰¾ä»»åŠ¡å¹¶å‘é€è¿›åº¦ï¼ˆæ¯æ¬¡éƒ½å‘é€ï¼Œä¸åªæ˜¯5ç§’é—´éš”ï¼‰
                task_found = False
                for task in pending_tasks:
                    if task.get("id") == task_id:
                        task_found = True
                        progress_pct = task.get("progress_pct")
                        if progress_pct is None:
                            progress_pct = 0
                        else:
                            progress_pct = int(progress_pct * 100)
                        
                        status = task.get("status", "processing")
                        
                        # æ¯æ¬¡è½®è¯¢éƒ½å‘é€è¿›åº¦æ›´æ–°
                        if stream:
                            debug_logger.log_info(f"Task {task_id} progress: {progress_pct}% (status: {status})")
                            yield self._format_stream_chunk(
                                reasoning_content=f"**Video Generation Progress**: {progress_pct}% ({status})\\n",
                                extra={"progress": progress_pct / 100.0}
                            )
                        break
                
                # 5. å¦‚æœä»»åŠ¡ä¸åœ¨pendingä¸­ï¼Œå‘é€"æ£€æŸ¥drafts"çš„SSE
                if not task_found:
                    if stream:
                        yield self._format_stream_chunk(
                            reasoning_content="Task completed, fetching final result from drafts...\\n"
                        )
                    
                    debug_logger.log_info(f"Task {task_id} not found in pending tasks, fetching from drafts...")
                    result = await self.sora_client.get_video_drafts(token)
                    # ... å¤„ç†drafts ...
```

### æ–¹æ¡ˆ2ï¼šç§»é™¤é—´éš”é™åˆ¶ï¼ˆç®€å•ä½†å¯èƒ½è¿‡äºé¢‘ç¹ï¼‰

ç›´æ¥ç§»é™¤`video_status_interval`çš„æ£€æŸ¥ï¼š

```python
# åŸä»£ç ï¼ˆç¬¬753-758è¡Œï¼‰
if stream and (current_time - last_status_output_time >= video_status_interval):
    last_status_output_time = current_time
    debug_logger.log_info(f"Task {task_id} progress: {progress_pct}% (status: {status})")
    yield self._format_stream_chunk(
        reasoning_content=f"**Video Generation Progress**: {progress_pct}% ({status})\\n"
    )

# ä¿®æ”¹ä¸º
if stream:
    debug_logger.log_info(f"Task {task_id} progress: {progress_pct}% (status: {status})")
    yield self._format_stream_chunk(
        reasoning_content=f"**Video Generation Progress**: {progress_pct}% ({status})\\n",
        extra={"progress": progress_pct / 100.0}
    )
```

### æ–¹æ¡ˆ3ï¼šæ·»åŠ è¯¦ç»†çš„è°ƒè¯•æ¨¡å¼

æ·»åŠ ä¸€ä¸ªé…ç½®é€‰é¡¹`debug_mode`ï¼Œåœ¨è°ƒè¯•æ¨¡å¼ä¸‹å‘é€æ‰€æœ‰æ—¥å¿—åˆ°SSEï¼š

```python
# åœ¨configä¸­æ·»åŠ 
debug_mode = config.get("debug_mode", False)

# åœ¨è½®è¯¢ä¸­
if stream and debug_mode:
    yield self._format_stream_chunk(
        reasoning_content=f"[DEBUG] Polling attempt {attempt + 1}, elapsed: {elapsed_time:.1f}s\\n"
    )
```

## å‰ç«¯æ˜¾ç¤ºå»ºè®®

å‰ç«¯`generate.js`å·²ç»æœ‰å¤„ç†è¿›åº¦çš„é€»è¾‘ï¼ˆç¬¬2793-2814è¡Œï¼‰ï¼š

```javascript
// è¿›åº¦ï¼šç»“æ„åŒ–å­—æ®µæˆ– reasoning_content ä¸­çš„ç™¾åˆ†æ¯”
const currentProgress =
  tasks.find((t) => t.id === taskId && !isNaN(parseFloat(t.progress)))?.progress ?? 0;
let progressVal = null;
const pctMatch = data.match(/(\d{1,3})%/);
if (pctMatch) progressMarkerSeen = true;
if (obj.progress !== undefined && !isNaN(parseFloat(obj.progress))) {
  progressVal = parseFloat(obj.progress);
  progressMarkerSeen = true;
}
```

å»ºè®®ï¼š
1. ç¡®ä¿åç«¯å‘é€çš„SSEåŒ…å«`progress`å­—æ®µ
2. åœ¨`reasoning_content`ä¸­åŒ…å«ç™¾åˆ†æ¯”ï¼ˆå¦‚`9%`ï¼‰ï¼Œå‰ç«¯ä¼šè‡ªåŠ¨æå–
3. è€ƒè™‘åœ¨UIä¸­æ˜¾ç¤º`reasoning_content`çš„å†…å®¹ï¼Œè®©ç”¨æˆ·çœ‹åˆ°è¯¦ç»†çŠ¶æ€

## æ¨èå®æ–½æ­¥éª¤

1. **ç«‹å³ä¿®å¤**ï¼šç§»é™¤`video_status_interval`é™åˆ¶ï¼Œæ¯æ¬¡è½®è¯¢éƒ½å‘é€è¿›åº¦ï¼ˆæ–¹æ¡ˆ2ï¼‰
2. **çŸ­æœŸä¼˜åŒ–**ï¼šæ·»åŠ æ›´å¤šå…³é”®æ­¥éª¤çš„SSEæ¨é€ï¼ˆæ–¹æ¡ˆ1ï¼‰
3. **é•¿æœŸæ”¹è¿›**ï¼šæ·»åŠ è°ƒè¯•æ¨¡å¼é…ç½®ï¼ˆæ–¹æ¡ˆ3ï¼‰

## ç›¸å…³æ–‡ä»¶

- `src/services/generation_handler.py` - ç¬¬679-900è¡Œï¼ˆ`_poll_task_result`æ–¹æ³•ï¼‰
- `static/js/generate.js` - ç¬¬2620-2920è¡Œï¼ˆSSEæµå¤„ç†é€»è¾‘ï¼‰
- `src/api/routes.py` - ç¬¬69-261è¡Œï¼ˆAPIç«¯ç‚¹ï¼‰
